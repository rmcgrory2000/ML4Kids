{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-bbcb99dd-d08a-42ac-a470-f834287be657",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/CNN%20Model-Minecraft%20Edition.png\" alt=\"CNN Title\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-0fafabd3-a567-4248-9cf1-d8c889023035",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%201.png\" alt=\"Page 1\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-d84881df-ddc5-4025-a468-0ce570820c1b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-a99fb5b9-1f6b-46da-81ca-9bef04e6829f",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Python Notebook Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-4d8348d8-2f35-4843-bc0f-6d3bbf4dd18e",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- The light grey boxes throughout this document are called cells.\n",
    "- To run a cell, simply click on it and press Shift and Enter.\n",
    "\n",
    "Now that you are equipped with everything you need to get through this notebook, let's begin!\n",
    "\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-6d54472e-1b4e-4844-825b-71fd02e28d1e",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## So...What is a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-17f21405-25ee-4aca-825e-29f284f8e876",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "If you recall back to the article, we talked a bit about image classification. Now we're going to take a peek behind the curtain and see how this magic really happens.\n",
    "\n",
    "These days, most image classification tasks are completed by something called a CNN. This stands for Convolutional Neural Network...it's quite the mouthful.\n",
    "\n",
    "To understand a CNN model, we're going to have to talk about something called a 'neural network'.\n",
    "\n",
    "A neural network will look at an image and try to break it down into recognizable pieces or features. For example, if we look at the image below, it will search the image pixel by pixel for any red, animal-shaped objects.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Starfish%20Image%20Classification.jpeg\" alt=\"Starfish Image Classification\" width=\"500\"></center>\n",
    "\n",
    "The neural network will repeat this process until it is confident that there is in fact a red animal in the picture.\n",
    "\n",
    "The information is passed through 'neurons'. Each neuron will carry information on a pixel (a small chunk of the image) and pass it on to another neuron which will use this information to predict that a red animal is present in the image.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Neural-Network.png\" alt=\"Neural Network Meme\" width=\"200\"></center>\n",
    "\n",
    "This image shows us a representation of what a neural network looks like. It looks super complicated, but it's basically a bunch of neurons passing information to each other to classify an image. This is a little insight into what's going on behind the scenes of the code you're running.\n",
    "\n",
    "However, there's more.\n",
    "\n",
    "Stay with me here.\n",
    "\n",
    "Now we know more about neural networks, but we still need to talk about the 'convolutional' part. As this is a bit of a tricky concept, we're going to try to simplify this as much as possible. So, if you would like to go into further depth, you can read this <a href=\"https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\"> article</a>.\n",
    "\n",
    "Basically, the convolutional part of the neural network computes a bunch of maths on the pixels in an image to explain how all the pixels in the image link together.\n",
    "\n",
    "\n",
    "To sum a CNN up, it's an algorithm that takes an image as an input and learns 'all on its own' how to identify the object in the image. Magic!\n",
    "\n",
    "Okay, we got there. Congratulations if you made it through this.\n",
    "\n",
    "Now you can get back to the fun bit. When you finally get to run the cell to build your model, feel proud that you know a little about what it is really doing!\n",
    "\n",
    "----------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-49b66c0e-f10e-4ba3-a21f-e4bb2c973d65",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-435136cb-d2fc-4997-a081-a15fef74250c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><table><tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%202.png\" alt=\"Page 2\" width=\"250\"></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%203.png\" alt=\"Page 3\" width=\"250\"></td>\n",
    "</tr></table></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-a1fbd473-94aa-4b1e-b143-660d466a374d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "- Libraries are made up of a group of functions.\n",
    "- To get access to the libraries, we must import them.\n",
    "- We use the word import next to the function that we want to use (as you will see in the cell below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-24c9aa62-4ec5-4452-b0ea-6acf6bca302c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Go ahead and run the code to import all of the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00015-26645a06-d37f-4f00-878b-e81aaa921cbc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4951,
    "execution_start": 1629197746175,
    "output_cleared": false,
    "source_hash": "6e8fabd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-590a137f-aec5-4395-bdbd-40a5672da68b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-30be8998-7044-49c9-b261-197ee62cd33f",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### How We View the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-981b0e15-3aae-48b7-b9d5-32feef959b53",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Here's an image of a Minecraft wolf.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Wolf.jpg\" alt=\"Original Wolf\" width=\"200\"></center>\n",
    "\n",
    "Pretty standard right? There's nothing unusual about this image and you don't have to think twice about using your eyes to look at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-24e434e4-b54f-46ab-8ad2-65ab29e38731",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### How the Computer Views the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00021-20a465b7-7507-4e27-aab0-a3bb5bfc5412",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "How do you look at an image? You just look at it without thinking twice about the process that goes on in your brain, right?\n",
    "\n",
    "Well, do computers have eyes? Of course the answer is no. Then how are they going to see the images so that they can learn from them?\n",
    "\n",
    "This line of code has the answers:\n",
    "\n",
    "```\n",
    "cv2.imread(image_of_minecraft_wolf)\n",
    "```\n",
    "Remember those libraries we imported earlier? Well one of the libraries is called 'cv2' and it is super handy for processing the images! \n",
    "\n",
    "cv2 has a function called 'imread()' that knows exactly how to read the image so that it looks like this:\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Blue%20Wolf.png\" alt=\"Blue Wolf\" width=\"250\"></center>\n",
    "\n",
    "We don't get to see the behind the scenes of what happens, but all we need to know is that the function takes the image we provide it with and makes it so that the computer will accept it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-4d5d7703-a9ca-4c76-a5cb-b7f3638ee114",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### How the Model Wants to Receive the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-0faefb62-eacf-4b50-b22c-479ce7a43631",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "I'm sure you have played spot the difference before. The two images that you compare are nearly always the same size, as this makes finding differences much easier.\n",
    "\n",
    "Well we can think of image classification to be similar to spot the difference in this way - the model would like the images to all be the same size so that it's easier to see what is the same and what is different in each one.\n",
    "\n",
    "Hence, we resize all of our images to the same size because our model prefers them to be that way. Again, we use cv2 to do this:\n",
    "\n",
    "```\n",
    "cv2.resize(image_of_minecraft_wolf, (80,80))\n",
    "```\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Resized%20Wolf.png\" alt=\"Resized Wolf\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-77b4342b-ddb6-471c-b724-4682e35c7c52",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "And now we're going to use the two cv2 functions we have just seen so that the computer can view the images and the model can receive them in a way that it prefers. \n",
    "\n",
    "We will take the images that we imported earlier, code them into the notebook and then resize the images.\n",
    "\n",
    "Let's get a start on that..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-331ed6f1-3743-413e-a40d-06b19089c6fd",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Read in and Resize the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00023-1dec9200-f1bc-4675-905f-1a3de2e1660b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><table><tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%204.png\" alt=\"Page 4\" width=\"250\"></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%205.png\" alt=\"Page 5\" width=\"250\"></td>\n",
    "</tr></table></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00024-ec5c308f-002c-434b-8e40-a1d835ddb188",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2429,
    "execution_start": 1629198782490,
    "output_cleared": true,
    "source_hash": "7c5d7c89",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Point to the location of the training dataset\n",
    "path_to_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Train Model with/\"\n",
    "\n",
    "#Decide the size that we would like each image to be (80x80)\n",
    "size_of_image = 80\n",
    "\n",
    "#Declare the mob categories that we want the model to guess from\n",
    "minecraft_mob_type = [\"sheep\", \"wolf\", \"zombie\"]\n",
    "training_data = []\n",
    "validation_data = []\n",
    "count = 0\n",
    "def create_data():\n",
    "    for category in minecraft_mob_type:\n",
    "\n",
    "        #Using os to navigate to each image\n",
    "        path = os.path.join(path_to_images, category,\"\")\n",
    "        class_num = minecraft_mob_type.index(category)\n",
    "        for mob_image in os.listdir(path):\n",
    "            try:\n",
    "\n",
    "                #Using cv2 to read in the image\n",
    "                image_array = cv2.imread(os.path.join(path,mob_image))\n",
    "\n",
    "                #Using cv2 to resize the Image\n",
    "                new_array = cv2.resize(image_array, (size_of_image, size_of_image))\n",
    "                if (count==0):\n",
    "\n",
    "                    #Adding the resized training image to a new pile of resized training images\n",
    "                    training_data.append([new_array, class_num])\n",
    "                else:\n",
    "\n",
    "                    #Adding the resized validation image to a new pile of resized validation images\n",
    "                    validation_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                continue\n",
    "                \n",
    "create_data()\n",
    "count += 1\n",
    "\n",
    "#Point to the location of the validation images\n",
    "path_to_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Validate  Model with\"\n",
    "create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00025-476cdc8f-c0c8-40e4-960e-661d5dd01cc9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now how about we check how many images we actually have for the training data and then the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-9eb6b214-92e3-4c0e-9fca-439aa04776d4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1629198795610,
    "output_cleared": false,
    "source_hash": "45930fce",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our training data has 500 images in it.\n"
     ]
    }
   ],
   "source": [
    "print('Our training data has', len(training_data), 'images in it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00027-c49b9946-6f49-4094-8e7b-e086b3bc2582",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1629198798007,
    "output_cleared": false,
    "source_hash": "b779a255",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our validation data has 76 images in it.\n"
     ]
    }
   ],
   "source": [
    "print('Our validation data has',len(validation_data), 'images in it.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-2235e39f-d6a9-4b5f-aa7e-021a49fef671",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "As long as there's more than 0 images in each dataset then I think it's safe to say we correctly located the images!\n",
    "\n",
    "That leads us to our next question,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00029-4b98cc0d-400b-49fb-9515-940dbec4fd23",
    "deepnote_cell_type": "text-cell-h3",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "### What are the Training and Validation Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-cfda5e67-2edf-45e9-9c72-93173111b751",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Think about any time you've had to study for an exam. First, you spend time learning from the notes that your teacher has given you. Next you have a go at some practice papers. Once you have finished the practice paper, you get to check where you went wrong and learn from your mistakes. You repeat this process until it is time for the real exam - you don't get to check your answers for this one.\n",
    "\n",
    "A machine learning model works rather similarly. The training images are like your notes which you spend time learning from. The validation images are like the practice papers which you spend time testing your knowledge and then checking where you went wrong so that you can improve. For the real exam, the model receives a 'testing' image set. This set is completely unseen to the model but is somewhat similar to the previous images it has studied from. Likewise, your exam paper will be similar but completely new to what you have seen before.\n",
    "\n",
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-ed6017bb-8f61-4878-bcf6-68b51ae329ab",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Shuffle the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-50050538-9caa-4977-a3a8-fb79e2efe26a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%206.png\" alt=\"Page 6\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00031-496692a6-4762-4c0b-b558-95fa645038ee",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "When we brought in our training and validation images, they were added in order. Let's take a look at what mobs are present in our first 10 images:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00032-9b4b6c9f-552b-460a-b721-254033f901c9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1629198923084,
    "output_cleared": false,
    "source_hash": "7090b354",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n",
      "sheep\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "  print(minecraft_mob_type[sample[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00033-fe9da165-88f9-4258-86cf-52931ef3b548",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We're literally looking at this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-a721da9b-45d2-4ce7-8d6f-c1460f87c2a9",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Stacked%20Sheep.jpg\" alt=\"Stacked Sheep\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00034-beb6455e-bd69-4fbc-83e7-1273298b3753",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "We don't want this. We want the mobs to be in a random order to make the model work hard in learning what a sheep or a wolf or a zombie looks like. We need it to find accurate patterns for each mob, such as that a wolf wears a collar. Otherwise, the model would just assume that the set of images are always ordered as sheep, followed by wolf, followed by zombie.\n",
    "\n",
    " Now we'll use that random library we talked about to randomly jumble all of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00035-9333b168-1eda-4310-966d-55d14aab8e0a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1629198929400,
    "output_cleared": true,
    "source_hash": "8ecb5765",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "random.shuffle(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00039-72e8f4be-0fed-4d63-89c8-6317961b25d6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Now we'll take another look at the first 10 images in our pile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00036-5c0b4eb4-8db3-4662-b457-6bdf2b93fbf7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1629198998367,
    "output_cleared": false,
    "source_hash": "7090b354",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sheep\n",
      "sheep\n",
      "zombie\n",
      "sheep\n",
      "sheep\n",
      "wolf\n",
      "zombie\n",
      "zombie\n",
      "sheep\n",
      "sheep\n"
     ]
    }
   ],
   "source": [
    "for sample in training_data[:10]:\n",
    "  print(minecraft_mob_type[sample[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00037-5d892598-a158-43af-b155-22debb712eb6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "That's much better. Our model can now find specific features among the mobs, like the sheep's silly eyes!\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-5dbe18ce-e01c-4358-aa58-6743a0869ed7",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Reshape and Normalize the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-a6143d64-f61d-4ce2-8b1b-66b0d8363b55",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><table><tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%207.png\" alt=\"Page 7\" width=\"250\"></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%208.png\" alt=\"Page 8\" width=\"250\"></td>\n",
    "</tr></table></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00038-eed8f163-4ccd-4426-965e-253235fb1c18",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We don't have to make much sense of this step, except that the model refuses to accept the images in any other way than what we are now presenting it with.\n",
    "\n",
    "Say we have an image of a zombie that is labelled 'zombie'. We will put that image into one pile, without any label, and then put the label in a separate pile. Then we will have a pile of images, and a pile of labels. We must give the Model the images and labels separate in this way.\n",
    "\n",
    "We will then reshape and normalize each image in the image pile. To normalize an image, we divide the image set by 255.0. Again, we won't go into the 'why', or what reshaping and normalizing really means,  but be aware that it's just to ensure that the model welcomes our images!\n",
    "\n",
    "We do this for both the training and the validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00039-65648354-33b8-450f-b811-b44a683950a8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 147,
    "execution_start": 1629199031802,
    "output_cleared": true,
    "source_hash": "dc00bd7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training Data\n",
    "training_features = []\n",
    "training_labels = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    training_features.append(features)\n",
    "    training_labels.append(label)\n",
    "\n",
    "training_features = np.array(training_features).reshape(-1, size_of_image, size_of_image, 3)\n",
    "training_labels = np.array(training_labels)\n",
    "\n",
    "training_features = training_features/255.0\n",
    "\n",
    "\n",
    "#Validation Data\n",
    "validation_features = []\n",
    "validation_labels = []\n",
    "\n",
    "for features, label in validation_data:\n",
    "    validation_features.append(features)\n",
    "    validation_labels.append(label)\n",
    "\n",
    "validation_features = np.array(validation_features).reshape(-1, size_of_image, size_of_image, 3)\n",
    "validation_labels = np.array(validation_labels)\n",
    "\n",
    "validation_features = validation_features/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00044-56b0efcb-c983-4fd1-9f94-2f06c6c2ade8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00049-96a3df32-ed9c-4c52-9446-7aebc52b55c2",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00050-c323afe2-f348-41fc-b807-06c60c06a487",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><table><tr>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%209.png\" alt=\"Page 9\" width=\"250\"></td>\n",
    "<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2010.png\" alt=\"Page 10\" width=\"250\"></td>\n",
    "</tr></table></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00040-29d2924a-42f8-4a5f-8598-819effa72fba",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "This next cell is really just computer magic that we don't need to fully understand right now. All that matters is the Model is the 'brain' that can classify our images.\n",
    "\n",
    "Let's get to work and build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00041-90635bdc-c1e1-44ba-b1cd-d76a5ae1c177",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 239,
    "execution_start": 1629199044190,
    "output_cleared": false,
    "source_hash": "ea9caf53",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 11:17:24.214112: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-08-17 11:17:24.217623: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-08-17 11:17:24.217648: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-17 11:17:24.217675: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-049853f5-89a6-480d-b709-935e6910c9c1): /proc/driver/nvidia/version does not exist\n",
      "2021-08-17 11:17:24.218000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-17 11:17:24.218188: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Each .add that you see is adding a layer to our Model\n",
    "#So each of these layers is performing some sort of calculation on an image\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(size_of_image, size_of_image, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00052-830cbf14-ab4d-4dee-b444-182f80cc2e2f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00052-e5a8db46-d6ed-4e5f-9800-559ebad8ada5",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00055-a5f11aca-4a0a-4b65-ae5b-079f368aa243",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2011.png\" alt=\"Page 11\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00052-e5c239cd-335c-4d52-90fc-211089a53961",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "We are going to run our Model for 50 epochs - this means the Model completely passes through the training images 50 times.\n",
    "\n",
    "We have set our batch size to 4 - as there are 500 training images, then in total the Model will have revised its knowledge 125 times each epoch. That means the Model will learn from its mistakes 6,250 times!\n",
    "\n",
    "It's no wonder then that this process is going to take time, so be patient. When you run the next cell, you will see the loading bar for each epoch. When an epoch completes, it will show accuracy loss, accuracy, validation loss and validation accuracy. We only really care about the validation accuracy (as this shows how well the Model is learning), so keep an eye on that as it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00042-b450f9f3-749a-4f35-86cd-424a9ef7c840",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 317282,
    "execution_start": 1629199068062,
    "output_cleared": false,
    "source_hash": "b6e908c4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 11:17:48.058539: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 38400000 exceeds 10% of free system memory.\n",
      "2021-08-17 11:17:48.156063: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-08-17 11:17:48.166947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199865000 Hz\n",
      "Epoch 1/50\n",
      "  4/125 [..............................] - ETA: 5s - loss: 1.2321 - accuracy: 0.30212021-08-17 11:17:49.035692: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n",
      "2021-08-17 11:17:49.036111: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n",
      "2021-08-17 11:17:49.041236: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 28387584 exceeds 10% of free system memory.\n",
      "2021-08-17 11:17:49.081347: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 1.1152 - accuracy: 0.3722 - val_loss: 1.0557 - val_accuracy: 0.4079\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 1.0024 - accuracy: 0.4640 - val_loss: 0.9111 - val_accuracy: 0.6579\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.8142 - accuracy: 0.6521 - val_loss: 0.7799 - val_accuracy: 0.6842\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.6698 - accuracy: 0.6619 - val_loss: 0.7508 - val_accuracy: 0.6316\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.6396 - accuracy: 0.6743 - val_loss: 0.6857 - val_accuracy: 0.7105\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.6266 - accuracy: 0.7238 - val_loss: 0.6534 - val_accuracy: 0.7368\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.5775 - accuracy: 0.6893 - val_loss: 0.6753 - val_accuracy: 0.7368\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.5898 - accuracy: 0.7250 - val_loss: 0.5969 - val_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.4918 - accuracy: 0.7854 - val_loss: 0.5637 - val_accuracy: 0.7632\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.5156 - accuracy: 0.7748 - val_loss: 0.5462 - val_accuracy: 0.6711\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.5398 - accuracy: 0.7818 - val_loss: 0.5082 - val_accuracy: 0.7632\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.4788 - accuracy: 0.8075 - val_loss: 0.4618 - val_accuracy: 0.7895\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.5085 - accuracy: 0.7724 - val_loss: 0.4747 - val_accuracy: 0.7632\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.4004 - accuracy: 0.8318 - val_loss: 0.5254 - val_accuracy: 0.8026\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3717 - accuracy: 0.8534 - val_loss: 0.4081 - val_accuracy: 0.8421\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3669 - accuracy: 0.8579 - val_loss: 0.4363 - val_accuracy: 0.8026\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.3476 - accuracy: 0.8610 - val_loss: 0.4723 - val_accuracy: 0.8026\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3821 - accuracy: 0.8395 - val_loss: 0.3811 - val_accuracy: 0.8553\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3032 - accuracy: 0.8692 - val_loss: 0.4533 - val_accuracy: 0.8289\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 6s 52ms/step - loss: 0.3337 - accuracy: 0.8807 - val_loss: 0.3865 - val_accuracy: 0.8289\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.3026 - accuracy: 0.8805 - val_loss: 0.4226 - val_accuracy: 0.7895\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.2501 - accuracy: 0.9165 - val_loss: 0.3452 - val_accuracy: 0.8684\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.3259 - accuracy: 0.8786 - val_loss: 0.3334 - val_accuracy: 0.8684\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2631 - accuracy: 0.9000 - val_loss: 0.3163 - val_accuracy: 0.8684\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2288 - accuracy: 0.9110 - val_loss: 0.3305 - val_accuracy: 0.8684\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2524 - accuracy: 0.9101 - val_loss: 0.2825 - val_accuracy: 0.8947\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.2138 - accuracy: 0.9196 - val_loss: 0.2471 - val_accuracy: 0.9079\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2367 - accuracy: 0.9075 - val_loss: 0.4832 - val_accuracy: 0.7368\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.2931 - accuracy: 0.8725 - val_loss: 0.2396 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.2514 - accuracy: 0.9196 - val_loss: 0.2288 - val_accuracy: 0.8947\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1809 - accuracy: 0.9310 - val_loss: 0.2589 - val_accuracy: 0.9211\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 6s 52ms/step - loss: 0.1979 - accuracy: 0.9157 - val_loss: 0.2284 - val_accuracy: 0.9211\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.2000 - accuracy: 0.9199 - val_loss: 0.2988 - val_accuracy: 0.9211\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1321 - accuracy: 0.9601 - val_loss: 0.1787 - val_accuracy: 0.9342\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.2089 - accuracy: 0.9283 - val_loss: 0.1969 - val_accuracy: 0.9474\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1548 - accuracy: 0.9512 - val_loss: 0.1943 - val_accuracy: 0.9211\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1622 - accuracy: 0.9496 - val_loss: 0.1924 - val_accuracy: 0.9342\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1546 - accuracy: 0.9570 - val_loss: 0.2159 - val_accuracy: 0.9342\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.1410 - accuracy: 0.9479 - val_loss: 0.1620 - val_accuracy: 0.9211\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.2059 - accuracy: 0.9194 - val_loss: 0.1381 - val_accuracy: 0.9605\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1616 - accuracy: 0.9371 - val_loss: 0.1683 - val_accuracy: 0.9474\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.1345 - accuracy: 0.9588 - val_loss: 0.1937 - val_accuracy: 0.9474\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0836 - accuracy: 0.9858 - val_loss: 0.1717 - val_accuracy: 0.9605\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.1222 - accuracy: 0.9594 - val_loss: 0.1557 - val_accuracy: 0.9605\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.1195 - accuracy: 0.9386 - val_loss: 0.1868 - val_accuracy: 0.9342\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 0.1216 - val_accuracy: 0.9605\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1028 - accuracy: 0.9493 - val_loss: 0.1393 - val_accuracy: 0.9605\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1186 - accuracy: 0.9512 - val_loss: 0.1334 - val_accuracy: 0.9211\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.0745 - accuracy: 0.9802 - val_loss: 0.1581 - val_accuracy: 0.9605\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.1050 - accuracy: 0.9593 - val_loss: 0.1403 - val_accuracy: 0.9605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f68583bbcd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_features, training_labels, batch_size=4, epochs=50, validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00054-f8a40992-9396-4bf0-9a8c-cedc926b1cea",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "And we're done! How did the val_accuracy turn out this time? There's always room for improvement - we could alter the model, add more training images or change the size of the images. It's all about what accuracy you require and you are happy with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00055-9364b055-0869-4040-ad57-08c2b169b2d1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00056-1a9f6693-86db-4807-8487-c987813cefe8",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00058-1cac31fa-796d-4325-aa41-fb19d2519e56",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2012.png\" alt=\"Page 12\" width=\"250\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00050-707a1df6-88d8-45fb-beb8-e5d07798fe79",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The next cell is where the Model is tested on everything it has learned so far. Remember back when we compared it to the exam that you sit with completely new unseen questions? The Model is about to sit an exam of its own with completely unseen images. It will have to use its knowledge to try to guess which minecraft mob is in each image.\n",
    "\n",
    "Let's run the cell and give the Model some peace and quiet to think!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00043-2d6ed922-3d22-495d-b5ee-705b0db57268",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3503,
    "execution_start": 1629199837602,
    "output_cleared": true,
    "source_hash": "5c5955e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Point to the location of the Test Images\n",
    "path_to_test_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Test Model with\"\n",
    "\n",
    "sheep_num_right = 0\n",
    "wolf_num_right = 0\n",
    "zombie_num_right = 0\n",
    "\n",
    "for category in minecraft_mob_type:\n",
    "    path = os.path.join(path_to_test_images, category,\"\")\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            new_array = cv2.resize(img_array, (size_of_image, size_of_image))\n",
    "            output = new_array.reshape(-1, size_of_image, size_of_image, 3)\n",
    "            prediction = model.predict(output)\n",
    "            if ((category==\"sheep\") & (np.argmax(prediction)==0)):\n",
    "                sheep_num_right +=1\n",
    "            elif ((category==\"wolf\") & (np.argmax(prediction)==1)):\n",
    "                wolf_num_right += 1\n",
    "            elif ((category==\"zombie\") & (np.argmax(prediction)==2)):\n",
    "                zombie_num_right += 1\n",
    "            else:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00052-d6a32c62-007b-4113-8a73-037586144630",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Time's up!\n",
    "\n",
    "Why don't we see just how well our model has done? Run the cell below and we'll find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00044-475d8ad6-b2a2-4766-b102-8255b5869db8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1629199846188,
    "output_cleared": false,
    "source_hash": "9dedd32b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model correctly guessed 90% of the sheep images.\n",
      "Our model correctly guessed 90% of the wolf images.\n",
      "Our model correctly guessed 95% of the zombie images.\n",
      "Overal our model scored 92% when tested.\n"
     ]
    }
   ],
   "source": [
    "sheep_percent = (sheep_num_right/20)\n",
    "format_sheep = \"{:.0%}\".format(sheep_percent)\n",
    "print(\"Our model correctly guessed\", format_sheep, \"of the sheep images.\")\n",
    "\n",
    "wolf_percent = (wolf_num_right/20)\n",
    "format_wolf = \"{:.0%}\".format(wolf_percent)\n",
    "print(\"Our model correctly guessed\", format_wolf, \"of the wolf images.\")\n",
    "\n",
    "zombie_percent = (zombie_num_right/20)\n",
    "format_zombie = \"{:.0%}\".format(zombie_percent)\n",
    "print(\"Our model correctly guessed\", format_zombie, \"of the zombie images.\")\n",
    "\n",
    "average_percent = ((sheep_percent + wolf_percent + zombie_percent)/3)\n",
    "format_average = \"{:.0%}\".format(average_percent)\n",
    "print(\"Overal our model scored\", format_average, \"when tested.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00062-c1272176-39b2-44b9-bac2-31c6022754d2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "That's a pretty good prediction right? Like we mentioned before, there's always room for improvement. And that's it. You have build a CNN that predicts if an image of a Minecraft mob is a sheep, wolf or zombie. Pretty cool right? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00061-5f24dd57-bd80-4fcb-be58-59de96246749",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00065-55212920-69e5-4a59-8811-70e6c5177ad3",
    "deepnote_cell_type": "text-cell-h2",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00065-427d143e-c2c2-44ed-80ec-15505b5cad44",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Well done for making it to the end! I hope you have enjoyed your experience with building a Machine Learning Model."
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "a46fa34f-291f-4f16-8e8e-7c495d3c12ae",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
