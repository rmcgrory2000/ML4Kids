{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "<image src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/CNN%20Model-Minecraft%20Edition.png\" alt=\"CNN Title\" width=\"1000\">",
   "metadata": {
    "tags": [],
    "cell_id": "00001-bbcb99dd-d08a-42ac-a470-f834287be657",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><image src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%201.png\" alt=\"Page 1\" width=\"250\"></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00001-0fafabd3-a567-4248-9cf1-d8c889023035",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "______",
   "metadata": {
    "tags": [],
    "cell_id": "00002-d84881df-ddc5-4025-a468-0ce570820c1b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Python Notebook Tutorial",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00002-a99fb5b9-1f6b-46da-81ca-9bef04e6829f",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "- The light grey boxes throughout this document are called cells.\n- To run a cell, simply click on it and press Shift and Enter.\n\nNow that you are equipped with everything you need to get through this notebook, let's begin!\n\n_______",
   "metadata": {
    "tags": [],
    "cell_id": "00003-4d8348d8-2f35-4843-bc0f-6d3bbf4dd18e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## So...What is a CNN?",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00004-6d54472e-1b4e-4844-825b-71fd02e28d1e",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "If you recall back to the article, we talked a bit about image classification. Now we're going to take a peek behind the curtain and see how this magic really happens.\n\nThese days, most image classification tasks are completed by something called a CNN. This stands for Convolutional Neural Network...it's quite the mouthful.\n\nTo understand a CNN model, we're going to have to talk about something called a 'neural network'.\n\nA neural network will look at an image and try to break it down into recognizable pieces or features. For example, if we look at the image below, it will search the image pixel by pixel for any red, animal-shaped objects.\n\n<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Starfish%20Image%20Classification.jpeg\" alt=\"Starfish Image Classification\" width=\"500\"></center>\n\nThe neural network will repeat this process until it is confident that there is in fact a red animal in the picture.\n\nThe information is passed through 'neurons'. Each neuron will carry information on a pixel (a small chunk of the image) and pass it on to another neuron which will use this information to predict that a red animal is present in the image.\n\n<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Neural-Network.png\" alt=\"Neural Network Meme\" width=\"200\"></center>\n\nThis image shows us a representation of what a neural network looks like. It looks super complicated, but it's basically a bunch of neurons passing information to each other to classify an image. This is a little insight into what's going on behind the scenes of the code you're running.\n\nHowever, there's more.\n\nStay with me here.\n\nNow we know more about neural networks, but we still need to talk about the 'convolutional' part. As this is a bit of a tricky concept, we're going to try to simplify this as much as possible. So, if you would like to go into further depth, you can read this <a href=\"https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/\"> article</a>.\n\nBasically, the convolutional part of the neural network computes a bunch of maths on the pixels in an image to explain how all the pixels in the image link together.\n\n\nTo sum a CNN up, it's an algorithm that takes an image as an input and learns 'all on its own' how to identify the object in the image. Magic!\n\nOkay, we got there. Congratulations if you made it through this.\n\nNow you can get back to the fun bit. When you finally get to run the cell to build your model, feel proud that you know a little about what it is really doing!\n\n----------\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00005-17f21405-25ee-4aca-825e-29f284f8e876",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00010-49b66c0e-f10e-4ba3-a21f-e4bb2c973d65",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><table><tr>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%202.png\" alt=\"Page 2\" width=\"250\"></td>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%203.png\" alt=\"Page 3\" width=\"250\"></td>\n</tr></table></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00011-435136cb-d2fc-4997-a081-a15fef74250c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "- Libraries are made up of a group of functions.\n- To get access to the libraries, we must import them.\n- We use the word import next to the function that we want to use (as you will see in the cell below).",
   "metadata": {
    "tags": [],
    "cell_id": "00013-a1fbd473-94aa-4b1e-b143-660d466a374d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Go ahead and run the code to import all of the necessary libraries.",
   "metadata": {
    "tags": [],
    "cell_id": "00013-24c9aa62-4ec5-4452-b0ea-6acf6bca302c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00015-26645a06-d37f-4f00-878b-e81aaa921cbc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6e8fabd4",
    "execution_start": 1629197746175,
    "execution_millis": 4951,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "from IPython.display import Image\nimport os\nimport cv2\nimport random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n",
   "outputs": [
    {
     "name": "stderr",
     "text": "2021-08-17 10:55:46.423448: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2021-08-17 10:55:46.423510: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "________",
   "metadata": {
    "tags": [],
    "cell_id": "00015-590a137f-aec5-4395-bdbd-40a5672da68b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### How We View the Image",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00016-30be8998-7044-49c9-b261-197ee62cd33f",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Here's an image of a Minecraft wolf.\n\n<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Wolf.jpg\" alt=\"Original Wolf\" width=\"200\"></center>\n\nPretty standard right? There's nothing unusual about this image and you don't have to think twice about using your eyes to look at it.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-981b0e15-3aae-48b7-b9d5-32feef959b53",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### How the Computer Views the Image",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00018-24e434e4-b54f-46ab-8ad2-65ab29e38731",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "How do you look at an image? You just look at it without thinking twice about the process that goes on in your brain, right?\n\nWell, do computers have eyes? Of course the answer is no. Then how are they going to see the images so that they can learn from them?\n\nThis line of code has the answers:\n\n```\ncv2.imread(image_of_minecraft_wolf)\n```\nRemember those libraries we imported earlier? Well one of the libraries is called 'cv2' and it is super handy for processing the images! \n\ncv2 has a function called 'imread()' that knows exactly how to read the image so that it looks like this:\n\n<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Blue%20Wolf.png\" alt=\"Blue Wolf\" width=\"250\"></center>\n\nWe don't get to see the behind the scenes of what happens, but all we need to know is that the function takes the image we provide it with and makes it so that the computer will accept it.",
   "metadata": {
    "tags": [],
    "cell_id": "00021-20a465b7-7507-4e27-aab0-a3bb5bfc5412",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### How the Model Wants to Receive the Image",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00020-4d5d7703-a9ca-4c76-a5cb-b7f3638ee114",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "I'm sure you have played spot the difference before. The two images that you compare are nearly always the same size, as this makes finding differences much easier.\n\nWell we can think of image classification to be similar to spot the difference in this way - the model would like the images to all be the same size so that it's easier to see what is the same and what is different in each one.\n\nHence, we resize all of our images to the same size because our model prefers them to be that way. Again, we use cv2 to do this:\n\n```\ncv2.resize(image_of_minecraft_wolf, (80,80))\n```\n\n<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Resized%20Wolf.png\" alt=\"Resized Wolf\" width=\"250\"></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00020-0faefb62-eacf-4b50-b22c-479ce7a43631",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "And now we're going to use the two cv2 functions we have just seen so that the computer can view the images and the model can receive them in a way that it prefers. \n\nWe will take the images that we imported earlier, code them into the notebook and then resize the images.\n\nLet's get a start on that...",
   "metadata": {
    "tags": [],
    "cell_id": "00023-77b4342b-ddb6-471c-b724-4682e35c7c52",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Read in and Resize the Images",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00024-331ed6f1-3743-413e-a40d-06b19089c6fd",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><table><tr>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%204.png\" alt=\"Page 4\" width=\"250\"></td>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%205.png\" alt=\"Page 5\" width=\"250\"></td>\n</tr></table></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00023-1dec9200-f1bc-4675-905f-1a3de2e1660b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-ec5c308f-002c-434b-8e40-a1d835ddb188",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7c5d7c89",
    "execution_start": 1629198782490,
    "execution_millis": 2429,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "#Point to the location of the training dataset\npath_to_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Train Model with/\"\n\n#Decide the size that we would like each image to be (80x80)\nsize_of_image = 80\n\n#Declare the mob categories that we want the model to guess from\nminecraft_mob_type = [\"sheep\", \"wolf\", \"zombie\"]\ntraining_data = []\nvalidation_data = []\ncount = 0\ndef create_data():\n    for category in minecraft_mob_type:\n\n        #Using os to navigate to each image\n        path = os.path.join(path_to_images, category,\"\")\n        class_num = minecraft_mob_type.index(category)\n        for mob_image in os.listdir(path):\n            try:\n\n                #Using cv2 to read in the image\n                image_array = cv2.imread(os.path.join(path,mob_image))\n\n                #Using cv2 to resize the Image\n                new_array = cv2.resize(image_array, (size_of_image, size_of_image))\n                if (count==0):\n\n                    #Adding the resized training image to a new pile of resized training images\n                    training_data.append([new_array, class_num])\n                else:\n\n                    #Adding the resized validation image to a new pile of resized validation images\n                    validation_data.append([new_array, class_num])\n            except Exception as e:\n                continue\n                \ncreate_data()\ncount += 1\n\n#Point to the location of the validation images\npath_to_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Validate  Model with\"\ncreate_data()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now how about we check how many images we actually have for the training data and then the validation data?",
   "metadata": {
    "tags": [],
    "cell_id": "00025-476cdc8f-c0c8-40e4-960e-661d5dd01cc9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00026-9eb6b214-92e3-4c0e-9fca-439aa04776d4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "45930fce",
    "execution_start": 1629198795610,
    "execution_millis": 9,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('Our training data has', len(training_data), 'images in it.')",
   "outputs": [
    {
     "name": "stdout",
     "text": "Our training data has 500 images in it.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00027-c49b9946-6f49-4094-8e7b-e086b3bc2582",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b779a255",
    "execution_start": 1629198798007,
    "execution_millis": 1,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('Our validation data has',len(validation_data), 'images in it.')",
   "outputs": [
    {
     "name": "stdout",
     "text": "Our validation data has 76 images in it.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "As long as there's more than 0 images in each dataset then I think it's safe to say we correctly located the images!\n\nThat leads us to our next question,",
   "metadata": {
    "tags": [],
    "cell_id": "00028-2235e39f-d6a9-4b5f-aa7e-021a49fef671",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### What are the Training and Validation Images?",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00029-4b98cc0d-400b-49fb-9515-940dbec4fd23",
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Think about any time you've had to study for an exam. First, you spend time learning from the notes that your teacher has given you. Next you have a go at some practice papers. Once you have finished the practice paper, you get to check where you went wrong and learn from your mistakes. You repeat this process until it is time for the real exam - you don't get to check your answers for this one.\n\nA machine learning model works rather similarly. The training images are like your notes which you spend time learning from. The validation images are like the practice papers which you spend time testing your knowledge and then checking where you went wrong so that you can improve. For the real exam, the model receives a 'testing' image set. This set is completely unseen to the model but is somewhat similar to the previous images it has studied from. Likewise, your exam paper will be similar but completely new to what you have seen before.\n\n_____________",
   "metadata": {
    "tags": [],
    "cell_id": "00030-cfda5e67-2edf-45e9-9c72-93173111b751",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Shuffle the Images",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00033-ed6017bb-8f61-4878-bcf6-68b51ae329ab",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%206.png\" alt=\"Page 6\" width=\"250\"></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00032-50050538-9caa-4977-a3a8-fb79e2efe26a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "When we brought in our training and validation images, they were added in order. Let's take a look at what mobs are present in our first 10 images:\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00031-496692a6-4762-4c0b-b558-95fa645038ee",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-9b4b6c9f-552b-460a-b721-254033f901c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7090b354",
    "execution_start": 1629198923084,
    "execution_millis": 6,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for sample in training_data[:10]:\n  print(minecraft_mob_type[sample[1]])",
   "outputs": [
    {
     "name": "stdout",
     "text": "sheep\nsheep\nsheep\nsheep\nsheep\nsheep\nsheep\nsheep\nsheep\nsheep\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "We're literally looking at this!",
   "metadata": {
    "tags": [],
    "cell_id": "00033-fe9da165-88f9-4258-86cf-52931ef3b548",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Stacked%20Sheep.jpg\" alt=\"Stacked Sheep\" width=\"200\">",
   "metadata": {
    "tags": [],
    "cell_id": "00034-a721da9b-45d2-4ce7-8d6f-c1460f87c2a9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "\n\nWe don't want this. We want the mobs to be in a random order to make the model work hard in learning what a sheep or a wolf or a zombie looks like. We need it to find accurate patterns for each mob, such as that a wolf wears a collar. Otherwise, the model would just assume that the set of images are always ordered as sheep, followed by wolf, followed by zombie.\n\n Now we'll use that random library we talked about to randomly jumble all of the images.",
   "metadata": {
    "tags": [],
    "cell_id": "00034-beb6455e-bd69-4fbc-83e7-1273298b3753",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00035-9333b168-1eda-4310-966d-55d14aab8e0a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8ecb5765",
    "execution_start": 1629198929400,
    "execution_millis": 4,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "random.shuffle(training_data)\nrandom.shuffle(validation_data)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now we'll take another look at the first 10 images in our pile:",
   "metadata": {
    "tags": [],
    "cell_id": "00039-72e8f4be-0fed-4d63-89c8-6317961b25d6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00036-5c0b4eb4-8db3-4662-b457-6bdf2b93fbf7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7090b354",
    "execution_start": 1629198998367,
    "execution_millis": 0,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for sample in training_data[:10]:\n  print(minecraft_mob_type[sample[1]])",
   "outputs": [
    {
     "name": "stdout",
     "text": "sheep\nsheep\nzombie\nsheep\nsheep\nwolf\nzombie\nzombie\nsheep\nsheep\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "That's much better. Our model can now find specific features among the mobs, like the sheep's silly eyes!\n\n\n---\n\n\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00037-5d892598-a158-43af-b155-22debb712eb6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Reshape and Normalize the Images",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00041-5dbe18ce-e01c-4358-aa58-6743a0869ed7",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><table><tr>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%207.png\" alt=\"Page 7\" width=\"250\"></td>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%208.png\" alt=\"Page 8\" width=\"250\"></td>\n</tr></table></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00041-a6143d64-f61d-4ce2-8b1b-66b0d8363b55",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "We don't have to make much sense of this step, except that the model refuses to accept the images in any other way than what we are now presenting it with.\n\nSay we have an image of a zombie that is labelled 'zombie'. We will put that image into one pile, without any label, and then put the label in a separate pile. Then we will have a pile of images, and a pile of labels. We must give the Model the images and labels separate in this way.\n\nWe will then reshape and normalize each image in the image pile. To normalize an image, we divide the image set by 255.0. Again, we won't go into the 'why', or what reshaping and normalizing really means,  but be aware that it's just to ensure that the model welcomes our images!\n\nWe do this for both the training and the validation images.",
   "metadata": {
    "tags": [],
    "cell_id": "00038-eed8f163-4ccd-4426-965e-253235fb1c18",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00039-65648354-33b8-450f-b811-b44a683950a8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dc00bd7f",
    "execution_start": 1629199031802,
    "execution_millis": 147,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "#Training Data\ntraining_features = []\ntraining_labels = []\n\nfor features, label in training_data:\n    training_features.append(features)\n    training_labels.append(label)\n\ntraining_features = np.array(training_features).reshape(-1, size_of_image, size_of_image, 3)\ntraining_labels = np.array(training_labels)\n\ntraining_features = training_features/255.0\n\n\n#Validation Data\nvalidation_features = []\nvalidation_labels = []\n\nfor features, label in validation_data:\n    validation_features.append(features)\n    validation_labels.append(label)\n\nvalidation_features = np.array(validation_features).reshape(-1, size_of_image, size_of_image, 3)\nvalidation_labels = np.array(validation_labels)\n\nvalidation_features = validation_features/255.0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "______",
   "metadata": {
    "tags": [],
    "cell_id": "00044-56b0efcb-c983-4fd1-9f94-2f06c6c2ade8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Building the Model",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00049-96a3df32-ed9c-4c52-9446-7aebc52b55c2",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><table><tr>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%209.png\" alt=\"Page 9\" width=\"250\"></td>\n<td><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2010.png\" alt=\"Page 10\" width=\"250\"></td>\n</tr></table></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00050-c323afe2-f348-41fc-b807-06c60c06a487",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "This next cell is really just computer magic that we don't need to fully understand right now. All that matters is the Model is the 'brain' that can classify our images.\n\nLet's get to work and build the model.",
   "metadata": {
    "tags": [],
    "cell_id": "00040-29d2924a-42f8-4a5f-8598-819effa72fba",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00041-90635bdc-c1e1-44ba-b1cd-d76a5ae1c177",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ea9caf53",
    "execution_start": 1629199044190,
    "execution_millis": 239,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "model = Sequential()\n\n#Each .add that you see is adding a layer to our Model\n#So each of these layers is performing some sort of calculation on an image\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(size_of_image, size_of_image, 3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(3, activation='softmax'))\n\nmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])",
   "outputs": [
    {
     "name": "stderr",
     "text": "2021-08-17 11:17:24.214112: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2021-08-17 11:17:24.217623: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2021-08-17 11:17:24.217648: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2021-08-17 11:17:24.217675: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-049853f5-89a6-480d-b709-935e6910c9c1): /proc/driver/nvidia/version does not exist\n2021-08-17 11:17:24.218000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2021-08-17 11:17:24.218188: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "______",
   "metadata": {
    "tags": [],
    "cell_id": "00052-830cbf14-ab4d-4dee-b444-182f80cc2e2f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Fitting the Model",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00052-e5a8db46-d6ed-4e5f-9800-559ebad8ada5",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2011.png\" alt=\"Page 11\" width=\"250\"></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00055-a5f11aca-4a0a-4b65-ae5b-079f368aa243",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "We are going to run our Model for 50 epochs - this means the Model completely passes through the training images 50 times.\n\nWe have set our batch size to 4 - as there are 500 training images, then in total the Model will have revised its knowledge 125 times each epoch. That means the Model will learn from its mistakes 6,250 times!\n\nIt's no wonder then that this process is going to take time, so be patient. When you run the next cell, you will see the loading bar for each epoch. When an epoch completes, it will show accuracy loss, accuracy, validation loss and validation accuracy. We only really care about the validation accuracy (as this shows how well the Model is learning), so keep an eye on that as it runs.",
   "metadata": {
    "tags": [],
    "cell_id": "00052-e5c239cd-335c-4d52-90fc-211089a53961",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00042-b450f9f3-749a-4f35-86cd-424a9ef7c840",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b6e908c4",
    "execution_start": 1629199068062,
    "execution_millis": 317282,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "model.fit(training_features, training_labels, batch_size=4, epochs=50, validation_data=(validation_features, validation_labels))",
   "outputs": [
    {
     "name": "stderr",
     "text": "2021-08-17 11:17:48.058539: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 38400000 exceeds 10% of free system memory.\n2021-08-17 11:17:48.156063: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n2021-08-17 11:17:48.166947: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199865000 Hz\nEpoch 1/50\n  4/125 [..............................] - ETA: 5s - loss: 1.2321 - accuracy: 0.30212021-08-17 11:17:49.035692: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n2021-08-17 11:17:49.036111: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n2021-08-17 11:17:49.041236: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 28387584 exceeds 10% of free system memory.\n2021-08-17 11:17:49.081347: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 21528576 exceeds 10% of free system memory.\n125/125 [==============================] - 9s 69ms/step - loss: 1.1152 - accuracy: 0.3722 - val_loss: 1.0557 - val_accuracy: 0.4079\nEpoch 2/50\n125/125 [==============================] - 6s 49ms/step - loss: 1.0024 - accuracy: 0.4640 - val_loss: 0.9111 - val_accuracy: 0.6579\nEpoch 3/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.8142 - accuracy: 0.6521 - val_loss: 0.7799 - val_accuracy: 0.6842\nEpoch 4/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.6698 - accuracy: 0.6619 - val_loss: 0.7508 - val_accuracy: 0.6316\nEpoch 5/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.6396 - accuracy: 0.6743 - val_loss: 0.6857 - val_accuracy: 0.7105\nEpoch 6/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.6266 - accuracy: 0.7238 - val_loss: 0.6534 - val_accuracy: 0.7368\nEpoch 7/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.5775 - accuracy: 0.6893 - val_loss: 0.6753 - val_accuracy: 0.7368\nEpoch 8/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.5898 - accuracy: 0.7250 - val_loss: 0.5969 - val_accuracy: 0.7500\nEpoch 9/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.4918 - accuracy: 0.7854 - val_loss: 0.5637 - val_accuracy: 0.7632\nEpoch 10/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.5156 - accuracy: 0.7748 - val_loss: 0.5462 - val_accuracy: 0.6711\nEpoch 11/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.5398 - accuracy: 0.7818 - val_loss: 0.5082 - val_accuracy: 0.7632\nEpoch 12/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.4788 - accuracy: 0.8075 - val_loss: 0.4618 - val_accuracy: 0.7895\nEpoch 13/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.5085 - accuracy: 0.7724 - val_loss: 0.4747 - val_accuracy: 0.7632\nEpoch 14/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.4004 - accuracy: 0.8318 - val_loss: 0.5254 - val_accuracy: 0.8026\nEpoch 15/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.3717 - accuracy: 0.8534 - val_loss: 0.4081 - val_accuracy: 0.8421\nEpoch 16/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.3669 - accuracy: 0.8579 - val_loss: 0.4363 - val_accuracy: 0.8026\nEpoch 17/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.3476 - accuracy: 0.8610 - val_loss: 0.4723 - val_accuracy: 0.8026\nEpoch 18/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.3821 - accuracy: 0.8395 - val_loss: 0.3811 - val_accuracy: 0.8553\nEpoch 19/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.3032 - accuracy: 0.8692 - val_loss: 0.4533 - val_accuracy: 0.8289\nEpoch 20/50\n125/125 [==============================] - 6s 52ms/step - loss: 0.3337 - accuracy: 0.8807 - val_loss: 0.3865 - val_accuracy: 0.8289\nEpoch 21/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.3026 - accuracy: 0.8805 - val_loss: 0.4226 - val_accuracy: 0.7895\nEpoch 22/50\n125/125 [==============================] - 7s 53ms/step - loss: 0.2501 - accuracy: 0.9165 - val_loss: 0.3452 - val_accuracy: 0.8684\nEpoch 23/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.3259 - accuracy: 0.8786 - val_loss: 0.3334 - val_accuracy: 0.8684\nEpoch 24/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.2631 - accuracy: 0.9000 - val_loss: 0.3163 - val_accuracy: 0.8684\nEpoch 25/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.2288 - accuracy: 0.9110 - val_loss: 0.3305 - val_accuracy: 0.8684\nEpoch 26/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.2524 - accuracy: 0.9101 - val_loss: 0.2825 - val_accuracy: 0.8947\nEpoch 27/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.2138 - accuracy: 0.9196 - val_loss: 0.2471 - val_accuracy: 0.9079\nEpoch 28/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.2367 - accuracy: 0.9075 - val_loss: 0.4832 - val_accuracy: 0.7368\nEpoch 29/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.2931 - accuracy: 0.8725 - val_loss: 0.2396 - val_accuracy: 0.8947\nEpoch 30/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.2514 - accuracy: 0.9196 - val_loss: 0.2288 - val_accuracy: 0.8947\nEpoch 31/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1809 - accuracy: 0.9310 - val_loss: 0.2589 - val_accuracy: 0.9211\nEpoch 32/50\n125/125 [==============================] - 6s 52ms/step - loss: 0.1979 - accuracy: 0.9157 - val_loss: 0.2284 - val_accuracy: 0.9211\nEpoch 33/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.2000 - accuracy: 0.9199 - val_loss: 0.2988 - val_accuracy: 0.9211\nEpoch 34/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1321 - accuracy: 0.9601 - val_loss: 0.1787 - val_accuracy: 0.9342\nEpoch 35/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.2089 - accuracy: 0.9283 - val_loss: 0.1969 - val_accuracy: 0.9474\nEpoch 36/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1548 - accuracy: 0.9512 - val_loss: 0.1943 - val_accuracy: 0.9211\nEpoch 37/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1622 - accuracy: 0.9496 - val_loss: 0.1924 - val_accuracy: 0.9342\nEpoch 38/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.1546 - accuracy: 0.9570 - val_loss: 0.2159 - val_accuracy: 0.9342\nEpoch 39/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.1410 - accuracy: 0.9479 - val_loss: 0.1620 - val_accuracy: 0.9211\nEpoch 40/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.2059 - accuracy: 0.9194 - val_loss: 0.1381 - val_accuracy: 0.9605\nEpoch 41/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1616 - accuracy: 0.9371 - val_loss: 0.1683 - val_accuracy: 0.9474\nEpoch 42/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.1345 - accuracy: 0.9588 - val_loss: 0.1937 - val_accuracy: 0.9474\nEpoch 43/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.0836 - accuracy: 0.9858 - val_loss: 0.1717 - val_accuracy: 0.9605\nEpoch 44/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.1222 - accuracy: 0.9594 - val_loss: 0.1557 - val_accuracy: 0.9605\nEpoch 45/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.1195 - accuracy: 0.9386 - val_loss: 0.1868 - val_accuracy: 0.9342\nEpoch 46/50\n125/125 [==============================] - 6s 51ms/step - loss: 0.1162 - accuracy: 0.9626 - val_loss: 0.1216 - val_accuracy: 0.9605\nEpoch 47/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.1028 - accuracy: 0.9493 - val_loss: 0.1393 - val_accuracy: 0.9605\nEpoch 48/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.1186 - accuracy: 0.9512 - val_loss: 0.1334 - val_accuracy: 0.9211\nEpoch 49/50\n125/125 [==============================] - 6s 50ms/step - loss: 0.0745 - accuracy: 0.9802 - val_loss: 0.1581 - val_accuracy: 0.9605\nEpoch 50/50\n125/125 [==============================] - 6s 49ms/step - loss: 0.1050 - accuracy: 0.9593 - val_loss: 0.1403 - val_accuracy: 0.9605\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 10,
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f68583bbcd0>"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "And we're done! How did the val_accuracy turn out this time? There's always room for improvement - we could alter the model, add more training images or change the size of the images. It's all about what accuracy you require and you are happy with.",
   "metadata": {
    "tags": [],
    "cell_id": "00054-f8a40992-9396-4bf0-9a8c-cedc926b1cea",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "_____",
   "metadata": {
    "tags": [],
    "cell_id": "00055-9364b055-0869-4040-ad57-08c2b169b2d1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Testing the Model",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00056-1a9f6693-86db-4807-8487-c987813cefe8",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<center><img src=\"https://raw.githubusercontent.com/rmcgrory2000/ML4Kids/main/CNN%20Model/Notebook%20Images/Page%2012.png\" alt=\"Page 12\" width=\"250\"></center>",
   "metadata": {
    "tags": [],
    "cell_id": "00058-1cac31fa-796d-4325-aa41-fb19d2519e56",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "The next cell is where the Model is tested on everything it has learned so far. Remember back when we compared it to the exam that you sit with completely new unseen questions? The Model is about to sit an exam of its own with completely unseen images. It will have to use its knowledge to try to guess which minecraft mob is in each image.\n\nLet's run the cell and give the Model some peace and quiet to think!",
   "metadata": {
    "tags": [],
    "cell_id": "00050-707a1df6-88d8-45fb-beb8-e5d07798fe79",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00043-2d6ed922-3d22-495d-b5ee-705b0db57268",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5c5955e4",
    "execution_start": 1629199837602,
    "execution_millis": 3503,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "#Point to the location of the Test Images\npath_to_test_images = \"/work/ML4Kids/CNN Model/CNN Model Image Dataset/Images to Test Model with\"\n\nsheep_num_right = 0\nwolf_num_right = 0\nzombie_num_right = 0\n\nfor category in minecraft_mob_type:\n    path = os.path.join(path_to_test_images, category,\"\")\n    for img in os.listdir(path):\n        try:\n            img_array = cv2.imread(os.path.join(path,img))\n            new_array = cv2.resize(img_array, (size_of_image, size_of_image))\n            output = new_array.reshape(-1, size_of_image, size_of_image, 3)\n            prediction = model.predict(output)\n            if ((category==\"sheep\") & (np.argmax(prediction)==0)):\n                sheep_num_right +=1\n            elif ((category==\"wolf\") & (np.argmax(prediction)==1)):\n                wolf_num_right += 1\n            elif ((category==\"zombie\") & (np.argmax(prediction)==2)):\n                zombie_num_right += 1\n            else:\n                continue\n        except Exception as e:\n            continue",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Time's up!\n\nWhy don't we see just how well our model has done? Run the cell below and we'll find out.",
   "metadata": {
    "tags": [],
    "cell_id": "00052-d6a32c62-007b-4113-8a73-037586144630",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00044-475d8ad6-b2a2-4766-b102-8255b5869db8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9dedd32b",
    "execution_start": 1629199846188,
    "execution_millis": 10,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "sheep_percent = (sheep_num_right/20)\nformat_sheep = \"{:.0%}\".format(sheep_percent)\nprint(\"Our model correctly guessed\", format_sheep, \"of the sheep images.\")\n\nwolf_percent = (wolf_num_right/20)\nformat_wolf = \"{:.0%}\".format(wolf_percent)\nprint(\"Our model correctly guessed\", format_wolf, \"of the wolf images.\")\n\nzombie_percent = (zombie_num_right/20)\nformat_zombie = \"{:.0%}\".format(zombie_percent)\nprint(\"Our model correctly guessed\", format_zombie, \"of the zombie images.\")\n\naverage_percent = ((sheep_percent + wolf_percent + zombie_percent)/3)\nformat_average = \"{:.0%}\".format(average_percent)\nprint(\"Overal our model scored\", format_average, \"when tested.\")",
   "outputs": [
    {
     "name": "stdout",
     "text": "Our model correctly guessed 90% of the sheep images.\nOur model correctly guessed 90% of the wolf images.\nOur model correctly guessed 95% of the zombie images.\nOveral our model scored 92% when tested.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "That's a pretty good prediction right? Like we mentioned before, there's always room for improvement. And that's it. You have build a CNN that predicts if an image of a Minecraft mob is a sheep, wolf or zombie. Pretty cool right? ",
   "metadata": {
    "tags": [],
    "cell_id": "00062-c1272176-39b2-44b9-bac2-31c6022754d2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "_______",
   "metadata": {
    "tags": [],
    "cell_id": "00061-5f24dd57-bd80-4fcb-be58-59de96246749",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Congratulations!",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00065-55212920-69e5-4a59-8811-70e6c5177ad3",
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Well done for making it to the end! I hope you have enjoyed your experience with building a Machine Learning Model.",
   "metadata": {
    "tags": [],
    "cell_id": "00065-427d143e-c2c2-44ed-80ec-15505b5cad44",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=049853f5-89a6-480d-b709-935e6910c9c1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "a46fa34f-291f-4f16-8e8e-7c495d3c12ae",
  "deepnote_execution_queue": []
 }
}